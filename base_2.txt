
@router.post("/upload-map-template")
async def upload_map_template(file: UploadFile = File(...)):
    """
    Strict validation:
      - Scan rows starting at SOURCE_START_ROW over REQUIRED_COLS.
      - If a row has ANY value in required cols but not ALL required cols filled -> 422 with details.
      - If no rows have any required data -> 422.
      - Only when ALL rows with data are fully valid -> map using COLUMN_MAP and write to template.

    Mapping:
      - Writes to TARGET_SHEET_NAME starting at TARGET_START_ROW.
      - COLUMN_MAP defines target_col -> source_col binding for each valid row.
    """
    allowed = {
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        "application/octet-stream"
    }
    if file.content_type not in allowed:
        raise HTTPException(415, f"Unsupported content type: {file.content_type}. Please upload a .xlsx file.")

    raw = await file.read()
    max_bytes = 25 * 1024 * 1024
    if len(raw) > max_bytes:
        raise HTTPException(413, f"File too large ({len(raw)} bytes). Max allowed is {max_bytes} bytes.")

    # ---- Load template
    template_path = settings.B_TEMPLATE_PATH
    if not template_path or not Path(template_path).exists():
        raise HTTPException(500, f"Template path not found: {template_path!r}")

    ext = Path(template_path).suffix.lower()
    keep_vba = ext in (".xlsm", ".xltm")

    wb_tmpl = load_workbook(
        template_path,
        data_only=False,
        keep_vba=keep_vba,
        keep_links=True,
        read_only=False,
    )
    wb_tmpl.template = False
    if settings.TARGET_SHEET_NAME not in wb_tmpl.sheetnames:
        raise HTTPException(500, f"Template sheet '{settings.TARGET_SHEET_NAME}' not found.")
    ws_tmpl = wb_tmpl[settings.TARGET_SHEET_NAME]

    # ---- Load source (coords mode)
    wb_src = load_workbook(BytesIO(raw), data_only=True, keep_links=True, read_only=True)
    src_ws = wb_src[wb_src.sheetnames[0]]  # first sheet

    # Precompute column indexes
    req_col_idx = {col: column_index_from_string(col) for col in settings.REQUIRED_COLS}
    map_src_idx = {tgt: column_index_from_string(src) for tgt, src in settings.COLUMN_MAP.items()}
    map_tgt_idx = {tgt: column_index_from_string(tgt) for tgt in settings.COLUMN_MAP.keys()}

    start_row = settings.SOURCE_START_ROW
    max_row = src_ws.max_row or start_row

    def _is_blank(v: Any) -> bool:
        return v is None or (isinstance(v, str) and v.strip() == "") or (not isinstance(v, str) and str(v).strip() == "")

    any_required_value_seen = False
    valid_rows: List[int] = []
    rows_with_missing: List[Dict[str, Any]] = []

    # ---- Strict validation over required columns
    for r in range(start_row, max_row + 1):
        # Read required values for this row
        vals = {col: src_ws.cell(row=r, column=req_col_idx[col]).value for col in settings.REQUIRED_COLS}
        all_blank = all(_is_blank(v) for v in vals.values())
        if all_blank:
            continue  # ignore fully empty rows (no required data present)

        any_required_value_seen = True
        missing = [col for col, v in vals.items() if _is_blank(v)]

        if missing:
            # Row has some data in required set but is incomplete -> collect error
            rows_with_missing.append({"row": r, "missing_required_columns": missing})
        else:
            # Fully valid row
            valid_rows.append(r)

    # ---- Decide outcome
    if not any_required_value_seen:
        raise HTTPException(
            status_code=422,
            detail={
                "message": f"No data found in required columns starting at row {settings.SOURCE_START_ROW}.",
                "required_columns": settings.REQUIRED_COLS,
                "first_data_row": settings.SOURCE_START_ROW,
            },
        )

    if rows_with_missing:
        # At least one partially-filled row -> fail fast with detailed report
        raise HTTPException(
            status_code=422,
            detail={
                "message": "Some rows have missing required fields. Please correct them and re-upload.",
                "required_columns": settings.REQUIRED_COLS,
                "first_data_row": settings.SOURCE_START_ROW,
                "rows_with_missing_required": rows_with_missing,
            },
        )

    if len(valid_rows) == 0:
        # Defensive guard (shouldn't happen if any_required_value_seen and no missing)
        raise HTTPException(
            status_code=422,
            detail={
                "message": "Data detected in required columns, but no fully valid rows were found.",
                "required_columns": settings.REQUIRED_COLS,
                "first_data_row": settings.SOURCE_START_ROW,
            },
        )

    # ---- All good -> write valid rows using COLUMN_MAP
    out_row = settings.TARGET_START_ROW
    for r in valid_rows:
        for tgt_col_letter, src_col_letter in settings.COLUMN_MAP.items():
            tgt_col_idx = map_tgt_idx[tgt_col_letter]
            src_col_idx = map_src_idx[tgt_col_letter]  # key is target letter in map_src_idx
            val = src_ws.cell(row=r, column=src_col_idx).value
            ws_tmpl.cell(row=out_row, column=tgt_col_idx, value=val)
        out_row += 1

    # Recalc & save
    try:
        wb_tmpl.calculation.fullCalcOnLoad = True
    except Exception:
        pass
    try:
        ws_tmpl.calculate_dimension(force=True)
    except Exception:
        pass

    out_dir = Path("./out"); out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / f"mapped_{int(time.time())}.xlsx"
    wb_tmpl.save(out_path)

    return FileResponse(
        str(out_path),
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        filename=out_path.name
    )
